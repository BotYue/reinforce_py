Experimental report of Actor-Critic Algorithm
Game: Breakout

___

Current configs
    - Optimizer: share RMSProp(learning_rate=7e-4, epsilon=0.1, decay=0.99)
    - max_steps: 80M
    - learning rate anneals to 0 during training process
    - t_max = 5
    - gradients clipping: global norms clipping (40.0)
    - entropy_ratio = 0.01
    - value loss coefficient = 0.5

Result
    After 40M training, the agent score average 40 points in an episode(5 lives).
